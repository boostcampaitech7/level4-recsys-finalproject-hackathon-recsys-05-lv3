import torch
import torch.optim as optim
import torch.nn.functional as F
import sys

class BPRLoss:
    def __init__(self,
                 recmodel,
                 args):
        self.config = args.optimizer
        self.model = recmodel
        self.weight_decay = self.config.args['weight_decay']
        self.lr = self.config.args['lr']
        optimizer_class  = getattr(optim,self.config.type)
        self.opt = optimizer_class(self.model.parameters(), lr=self.lr)
        # self.opt = optim.Adam(recmodel.parameters(), lr=self.lr)

        self.args = args

    def predict(self, users, pos, neg):
        
        if self.args.model == "CLCRec":
            loss, reg_loss = self.model.clc_loss(users, pos, neg)
        else:
            loss, reg_loss = self.model.bpr_loss(users, pos, neg)
            
        reg_loss = reg_loss*self.weight_decay
        loss = loss + reg_loss

        self.opt.zero_grad()
        loss.backward()
        self.opt.step()

        return loss.cpu().item()
    
class BPRLossWithReg:
    def __init__(self, recmodel, args):
        self.config = args.optimizer
        self.model = recmodel
        self.weight_decay = self.config.args['weight_decay']
        self.reg_weight = self.config.args.get('reg_weight', 0.000001)  # Graph Regularization ê°€ì¤‘ì¹˜ ì¶”ê°€
        self.lr = self.config.args['lr']

        optimizer_class = getattr(optim, self.config.type)  # ê°€ë³€ì ì¸ Optimizer ì‚¬ìš©
        self.opt = optimizer_class(recmodel.parameters(), lr=self.lr)

    def predict(self, users, pos, neg):
        """
        BPR Loss + Graph Regularization Loss ì ìš©.
        """
        # ê¸°ì¡´ BPR Loss ê³„ì‚°
        loss, reg_loss = self.model.bpr_loss(users, pos, neg)
        reg_loss = reg_loss * self.weight_decay  # ê¸°ì¡´ ì •ê·œí™”

        # Graph Regularization Loss ê³„ì‚°
        graph_reg_loss = self.graph_regularization_loss(self.model)
        graph_reg_loss = graph_reg_loss * self.reg_weight  # ê°€ì¤‘ì¹˜ ì ìš©

        # ìµœì¢… Loss ê³„ì‚°
        total_loss = loss + reg_loss + graph_reg_loss

        # ì—­ì „íŒŒ ë° ìµœì í™”
        self.opt.zero_grad()
        total_loss.backward()
        self.opt.step()
        
        # ë””ë²„ê¹…ìš©
        # print(f"pos: {pos[:5]}, neg: {neg[:5]}")
        # print(f"users_emb[:5]: {users_emb[:5]}")
        # print(f"pos_emb[:5]: {pos_emb[:5]}")
        # print(f"neg_emb[:5]: {neg_emb[:5]}")
        # sys.stdout.flush()
        print(f"ğŸ”¹ total_loss: {total_loss.item()}, loss: {loss.item()}, reg_loss: {reg_loss.item()}, graph_reg_loss: {graph_reg_loss.item()}")
        sys.stdout.flush()


        return total_loss.cpu().item()

    def graph_regularization_loss(self, model):
        """
        Graph Regularization Loss ê³„ì‚°.
        L_reg = Î£ w_ij ||E_i - E_j||^2
        """
        item_embeddings = model.embedding_item.weight  # ì•„ì´í…œ ì„ë² ë”© ê°€ì ¸ì˜¤ê¸°
        similarity_matrix = self.compute_similarity_matrix(item_embeddings)  # ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°
        # ë””ë²„ê¹…: í¬ê¸° í™•ì¸
        # print(f"item_embeddings.shape: {item_embeddings.shape}")  # ì˜ˆìƒ: (3533, 64)
        # print(f"similarity_matrix.shape: {similarity_matrix.shape}")  # ì˜ˆìƒ: (3533, 3533)
        # sys.stdout.flush()
        # Debug: ìœ ì‚¬ë„ í–‰ë ¬ ê°’ í™•ì¸
        print(f"similarity_matrix min: {similarity_matrix.min().item()}, max: {similarity_matrix.max().item()}")
        print(f"item_embeddings min: {item_embeddings.min().item()}, max: {item_embeddings.max().item()}")
        sys.stdout.flush()

        # í¬ê¸° ì¡°ì • í›„ ê³„ì‚°
        reg_loss = torch.sum(similarity_matrix.unsqueeze(-1) * (item_embeddings.unsqueeze(1) - item_embeddings.unsqueeze(0)).pow(2))
        # reg_loss = torch.sum(similarity_matrix * (item_embeddings.unsqueeze(1) - item_embeddings.unsqueeze(0)).pow(2))

        # Debug: reg_loss ê°’ í™•ì¸
        print(f"graph_reg_loss (before scaling): {reg_loss.item()}")
        sys.stdout.flush()
        
        return reg_loss

    def compute_similarity_matrix(self, embeddings):
        """
        Cosine Similarity ê¸°ë°˜ìœ¼ë¡œ ì•„ì´í…œ ê°„ ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°.
        """
        norm_embeddings = F.normalize(embeddings, p=2, dim=1)  # ì •ê·œí™”
        similarity_matrix = torch.mm(norm_embeddings, norm_embeddings.t())  # Cosine Similarity ê³„ì‚°

        # ë””ë²„ê¹…: ìŒìˆ˜ ê°’ ë°©ì§€ (Cosine SimilarityëŠ” -1 ~ 1 ë²”ìœ„ì´ë¯€ë¡œ, 0 ì´ìƒìœ¼ë¡œ ì„¤ì •)
        similarity_matrix = torch.clamp(similarity_matrix, min=0)

        return similarity_matrix